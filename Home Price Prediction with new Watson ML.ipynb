{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Watson ML for Developers"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Import, Clean, and Analyze\u00a0Data\nWe are going to use PixieDust to load and visualize our data."
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20191119223446-0004\nKERNEL_ID = 5b18f11f-a7b8-44f1-9047-a30024b6823c\nPixiedust database opened successfully\n"
                },
                {
                    "data": {
                        "text/html": "\n        <div style=\"margin:10px\">\n            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n            </a>\n            <span>Pixiedust version 1.1.16</span>\n        </div>\n        ",
                        "text/plain": "<IPython.core.display.HTML object>"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": "<div>Warning: You are not running the latest version of PixieDust. Current is 1.1.16, Latest is 1.1.17</div>",
                        "text/plain": "<IPython.core.display.HTML object>"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": "\n                <div>Please copy and run the following command in a new cell to upgrade: <span style=\"background-color:#ececec;font-family:monospace;padding:0 5px\">!pip install --user --upgrade pixiedust</span></div>\n            ",
                        "text/plain": "<IPython.core.display.HTML object>"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": "<div>Please restart kernel after upgrading.</div>",
                        "text/plain": "<IPython.core.display.HTML object>"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": "import pixiedust"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Downloading 'https://raw.githubusercontent.com/markwatsonatx/watson-ml-for-developers/master/data/house-prices.csv' from https://raw.githubusercontent.com/markwatsonatx/watson-ml-for-developers/master/data/house-prices.csv\nDownloaded 92 bytes\nCreating pandas DataFrame for 'https://raw.githubusercontent.com/markwatsonatx/watson-ml-for-developers/master/data/house-prices.csv'. Please wait...\nLoading file using 'pandas'\nSuccessfully created pandas DataFrame for 'https://raw.githubusercontent.com/markwatsonatx/watson-ml-for-developers/master/data/house-prices.csv'\n"
                }
            ],
            "source": "df = pixiedust.sampleData(\"https://raw.githubusercontent.com/markwatsonatx/watson-ml-for-developers/master/data/house-prices.csv\", forcePandas=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "handlerId": "tableView"
                    }
                }
            },
            "outputs": [],
            "source": "display(df)\nfrom pyspark.sql import SQLContext\n#print sc\n#sqlCtx = SQLContext(sc)\nsqlCtx.createDataFrame(df).show()\nspdf=sqlCtx.createDataFrame(df)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Build a Machine Learning\u00a0Model with Spark ML "
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "from pyspark.ml import Pipeline\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.feature import VectorAssembler"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "assembler = VectorAssembler(inputCols=['SquareFeet','Bedrooms'],outputCol=\"features\")\nlr = LinearRegression(labelCol='Price', featuresCol='features')\npipeline = Pipeline(stages=[assembler, lr])\nmodel = pipeline.fit(spdf)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Test the\u00a0Model witl Spark ML"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "def get_prediction(square_feet, num_bedrooms):\n    request_df = spark.createDataFrame([(square_feet, num_bedrooms)], ['SquareFeet','Bedrooms'])\n    response_df = model.transform(request_df)\n    return response_df"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "+----------+--------+------------+------------------+\n|SquareFeet|Bedrooms|    features|        prediction|\n+----------+--------+------------+------------------+\n|      2400|       4|[2400.0,4.0]|137499.99999999968|\n+----------+--------+------------+------------------+\n\n"
                }
            ],
            "source": "response = get_prediction(2400, 4)\nresponse.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Save the\u00a0Model and Training Data"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "# If you rerun this cell, save model and training data with new name\nmodel.save( \"Home Prices Model Final1\" )\nspdf.write.save( \"training-data-Final1.parquet\" )"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Deploy Model to Watson ML"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": "import json\nimport requests\nimport urllib3"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting watson-machine-learning-client\n  Using cached https://files.pythonhosted.org/packages/12/67/66db412f00d19bfdc5725078bff373787513bfb14320f2804b9db3abb53a/watson_machine_learning_client-1.0.378-py3-none-any.whl\nCollecting tabulate (from watson-machine-learning-client)\nCollecting certifi (from watson-machine-learning-client)\n  Using cached https://files.pythonhosted.org/packages/18/b0/8146a4f8dd402f60744fa380bc73ca47303cccf8b9190fd16a827281eac2/certifi-2019.9.11-py2.py3-none-any.whl\nCollecting urllib3 (from watson-machine-learning-client)\n  Using cached https://files.pythonhosted.org/packages/b4/40/a9837291310ee1ccc242ceb6ebfd9eb21539649f193a7c8c86ba15b98539/urllib3-1.25.7-py2.py3-none-any.whl\nCollecting pandas (from watson-machine-learning-client)\n  Using cached https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl\nCollecting requests (from watson-machine-learning-client)\n  Using cached https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl\nCollecting tqdm (from watson-machine-learning-client)\n  Using cached https://files.pythonhosted.org/packages/b9/08/8505f192efc72bfafec79655e1d8351d219e2b80b0dec4ae71f50934c17a/tqdm-4.38.0-py2.py3-none-any.whl\nCollecting ibm-cos-sdk (from watson-machine-learning-client)\nCollecting lomond (from watson-machine-learning-client)\n  Using cached https://files.pythonhosted.org/packages/0f/b1/02eebed49c754b01b17de7705caa8c4ceecfb4f926cdafc220c863584360/lomond-0.3.3-py2.py3-none-any.whl\nCollecting numpy>=1.13.3 (from pandas->watson-machine-learning-client)\n  Using cached https://files.pythonhosted.org/packages/d2/ab/43e678759326f728de861edbef34b8e2ad1b1490505f20e0d1f0716c3bf4/numpy-1.17.4-cp36-cp36m-manylinux1_x86_64.whl\nCollecting python-dateutil>=2.6.1 (from pandas->watson-machine-learning-client)\n  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\nCollecting pytz>=2017.2 (from pandas->watson-machine-learning-client)\n  Using cached https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl\nCollecting chardet<3.1.0,>=3.0.2 (from requests->watson-machine-learning-client)\n  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\nCollecting idna<2.9,>=2.5 (from requests->watson-machine-learning-client)\n  Using cached https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl\nCollecting jmespath<1.0.0,>=0.7.1 (from ibm-cos-sdk->watson-machine-learning-client)\n  Using cached https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\nCollecting ibm-cos-sdk-s3transfer==2.5.5 (from ibm-cos-sdk->watson-machine-learning-client)\nCollecting ibm-cos-sdk-core==2.5.5 (from ibm-cos-sdk->watson-machine-learning-client)\nCollecting six>=1.10.0 (from lomond->watson-machine-learning-client)\n  Using cached https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\nCollecting docutils<0.16,>=0.10 (from ibm-cos-sdk-core==2.5.5->ibm-cos-sdk->watson-machine-learning-client)\n  Using cached https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl\n\u001b[31mtensorflow 1.13.1 requires tensorboard<1.14.0,>=1.13.0, which is not installed.\u001b[0m\n\u001b[31mbotocore 1.12.82 has requirement urllib3<1.25,>=1.20, but you'll have urllib3 1.25.7 which is incompatible.\u001b[0m\nInstalling collected packages: tabulate, certifi, urllib3, numpy, six, python-dateutil, pytz, pandas, chardet, idna, requests, tqdm, jmespath, docutils, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer, ibm-cos-sdk, lomond, watson-machine-learning-client\nSuccessfully installed certifi-2019.9.11 chardet-3.0.4 docutils-0.15.2 ibm-cos-sdk-2.5.5 ibm-cos-sdk-core-2.5.5 ibm-cos-sdk-s3transfer-2.5.5 idna-2.8 jmespath-0.9.4 lomond-0.3.3 numpy-1.17.4 pandas-0.25.3 python-dateutil-2.8.1 pytz-2019.3 requests-2.22.0 six-1.13.0 tabulate-0.8.6 tqdm-4.38.0 urllib3-1.25.7 watson-machine-learning-client-1.0.378\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/watson_machine_learning_client already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/requests-2.22.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/jmespath-0.9.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/docutils already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/python_dateutil-2.8.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/ibm_cos_sdk-2.5.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/lomond-0.3.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/tqdm-4.38.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/ibm_cos_sdk_s3transfer-2.5.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/pytz-2019.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/urllib3-1.25.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/pandas-0.25.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/ibm_botocore already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/pandas already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/idna already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/numpy-1.17.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/watson_machine_learning_client-1.0.378.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/chardet already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/ibm_s3transfer already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/idna-2.8.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/ibm_cos_sdk_core-2.5.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/tqdm already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/docutils-0.15.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/jmespath already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/dateutil already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/tabulate.py already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/requests already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/ibm_boto3 already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/certifi-2019.9.11.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/tabulate-0.8.6.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/pytz already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/chardet-3.0.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/six-1.13.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/lomond already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n"
                }
            ],
            "source": "!pip install watson-machine-learning-client"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Fill in Your Watson ML Credentials"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient\nwml_credentials = { \"apikey\" : \"5N2kiV107Xi4zaSHtBgksTYFmXKpxgeW3-ua4MOGGsPw\", \n                     \"url\" : \"https://us-south.ml.cloud.ibm.com\",\n                     \"instance_id\" : \"0cb8b342-7712-4f9d-a3ba-361ae98b4ff1\" \n                  }\n\nclient = WatsonMachineLearningAPIClient( wml_credentials )"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "{'apikey': '5N2kiV107Xi4zaSHtBgksTYFmXKpxgeW3-ua4MOGGsPw',\n 'iam_apikey_description': 'Auto-generated for key 4ff38372-a28f-4f1b-b5b3-0e8376b03d87',\n 'iam_apikey_name': 'Service credentials-1',\n 'iam_role_crn': 'crn:v1:bluemix:public:iam::::serviceRole:Writer',\n 'iam_serviceid_crn': 'crn:v1:bluemix:public:iam-identity::a/9e38ead7bd5743c3bd47f0b78c580073::serviceid:ServiceId-8eeeb26f-5352-47d7-80c6-caa199ff94ed',\n 'instance_id': '0cb8b342-7712-4f9d-a3ba-361ae98b4ff1',\n 'url': 'https://us-south.ml.cloud.ibm.com'}"
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Service Credential from my Watson ML Service\n{\n  \"apikey\": \"5N2kiV107Xi4zaSHtBgksTYFmXKpxgeW3-ua4MOGGsPw\",\n  \"iam_apikey_description\": \"Auto-generated for key 4ff38372-a28f-4f1b-b5b3-0e8376b03d87\",\n  \"iam_apikey_name\": \"Service credentials-1\",\n  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/9e38ead7bd5743c3bd47f0b78c580073::serviceid:ServiceId-8eeeb26f-5352-47d7-80c6-caa199ff94ed\",\n  \"instance_id\": \"0cb8b342-7712-4f9d-a3ba-361ae98b4ff1\",\n  \"url\": \"https://us-south.ml.cloud.ibm.com\"\n}\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Store the model in Watson ML"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": "from pyspark.ml import PipelineModel\npipeline_model = PipelineModel.load( \"Home Prices Model\" )\npipeline = Pipeline( stages = pipeline_model.stages )\ntrain = spark.read.load( \"training-data.parquet\" )"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": "# Store the PipelineModel in the Watson Machine Learning repository\nmodel_details = client.repository.store_model( pipeline_model, 'Home Prices model', training_data=train, pipeline=pipeline )"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Deploy the stored model in Watson ML service"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: '1ff28b6e-8e4a-4e9c-891a-0b824b76154b' started\n\n#######################################################################################\n\n\nINITIALIZING\nDEPLOY_SUCCESS\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='ab08384b-64ba-41eb-ac16-37ded9968724'\n------------------------------------------------------------------------------------------------\n\n\n"
                }
            ],
            "source": "# Deploy the stored model as an online web service deployment\nmodel_id = model_details[\"metadata\"][\"guid\"]\ndeployment_details = client.deployments.create( artifact_uid=model_id, name=\"Spark MLlib model deployment\" )"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "{'fields': ['SquareFeet', 'Bedrooms', 'features', 'prediction'],\n 'values': [[2400, 4, [2400.0, 4.0], 137499.99999999968]]}"
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "#### Test the deployment\nmodel_endpoint_url = client.deployments.get_scoring_url( deployment_details )\npayload = {'fields': ['SquareFeet','Bedrooms'], 'values': [[2400, 4]]}\nclient.deployments.score( model_endpoint_url, payload )"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "+----------+--------+------------+------------------+\n|SquareFeet|Bedrooms|    features|        prediction|\n+----------+--------+------------+------------------+\n|      2400|       4|[2400.0,4.0]|137499.99999999968|\n+----------+--------+------------+------------------+\n\n"
                }
            ],
            "source": "#### Testing the model locally gets the same results (testing again similar as above in cell \"Test the\u00a0Model witl Spark ML\")\ntest_df = spark.createDataFrame([(2400, 4)], ['SquareFeet','Bedrooms'])\nresponse_df = model.transform(test_df).show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with Spark",
            "language": "python3",
            "name": "python36"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}